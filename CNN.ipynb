{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMHk1PFwdVl/q+L4ucsXGPc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PetchMa/deeplearning_fundamentals/blob/main/CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build CNN Model\n",
        "\n",
        "In this notebook we once again try to build a CNN model from scratch uisng JAX and other packages with as little help as possible as means of learning explicitly how these algorithms work."
      ],
      "metadata": {
        "id": "jLUbMOhjyN32"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iIToHB_dyKKT"
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "import numpy as np\n",
        "import jax.numpy as jnp\n",
        "from jax.scipy.special import logsumexp\n",
        "from jax import jit, vmap, grad, pmap,value_and_grad\n",
        "\n",
        "from torchvision.datasets import MNIST\n",
        "from torch.utils.data import DataLoader \n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convolutional Layers\n",
        "Convolutional networks are special because of these layers that slides kernels around images and \"aggregate\" data from adjacent pixels. We will implement this from scratch as the following function below. Note this is absolutely digustingly slow because of the implementation and in reality there exists smarter stride tricks which I've yet to fully understand. However the function below captures the core mechanics of the CNN model.\n",
        "\n",
        "Besides just the convolutional layer we also have a pooling layer that reduces the dimensionality of the data.\n",
        "\n",
        "Also keep in mind that this is uses python LISTS in the convolutional layer and the reason why is because JAX is completely functional and thus the arrays are immutable and cannot be assigned values and thus to store the data I can't update values like you'd normally would in a numpy array. Yes I am away this is quite disgusting but at least it works..."
      ],
      "metadata": {
        "id": "s5oaEcdNy7rm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@jit\n",
        "def conv2d(image, filter):\n",
        "  # Height and width of output image\n",
        "  Hout = image.shape[0] - filter.shape[0] + 1\n",
        "  Wout = image.shape[1] - filter.shape[1] + 1\n",
        "  output = []\n",
        "  \n",
        "  # loops through the h index\n",
        "  for i in range(Hout):\n",
        "    # loops through the w index\n",
        "    rows = []\n",
        "    for j in range(Wout):\n",
        "      # loops through the depth of the filters\n",
        "      depth  = []\n",
        "      for cout in range(filter.shape[2]):\n",
        "        depth.append(jnp.multiply(image[ i:i+filter.shape[0], j:j+filter.shape[1], :], filter[:,:,cout]).sum())\n",
        "      rows.append(depth)\n",
        "    output.append(rows)\n",
        "  return jnp.array(output)\n",
        "\n",
        "# @jax.jit\n",
        "# def conv2d(image, filter):\n",
        "#   # Height and width of output image\n",
        "#   Hout = image.shape[0] - filter.shape[0] + 1\n",
        "#   Wout = image.shape[1] - filter.shape[1] + 1\n",
        "#   print([Hout, Wout, filter.shape[2]])\n",
        "#   output = np.zeros([Hout, Wout, filter.shape[2]])\n",
        "  \n",
        "#   # loops through the h index\n",
        "#   for i in range(Hout):\n",
        "#     # loops through the w index\n",
        "#     rows = []\n",
        "#     for j in range(Wout):\n",
        "#       # loops through the depth of the filters\n",
        "#       depth  = []\n",
        "#       for cout in range(filter.shape[2]):\n",
        "#         print( jnp.multiply(image[ i:i+filter.shape[0], j:j+filter.shape[1], :], filter[:,:,cout]).sum())\n",
        "#         output[i,j,cout] = jnp.multiply(image[ i:i+filter.shape[0], j:j+filter.shape[1], :], filter[:,:,cout]).sum().astype(float)\n",
        "#   return jnp.array(output)\n",
        "\n",
        "@jit\n",
        "def pooling(mat,ksize,method='max',pad=False):\n",
        "\n",
        "    m, n = mat.shape[:2]\n",
        "    ky,kx=ksize\n",
        "\n",
        "    _ceil=lambda x,y: int(jnp.ceil(x/float(y)))\n",
        "\n",
        "    if pad:\n",
        "        ny=_ceil(m,ky)\n",
        "        nx=_ceil(n,kx)\n",
        "        size=(ny*ky, nx*kx)+mat.shape[2:]\n",
        "        mat_pad=jnp.full(size,jnp.nan)\n",
        "        mat_pad[:m,:n,...]=mat\n",
        "    else:\n",
        "        ny=m//ky\n",
        "        nx=n//kx\n",
        "        mat_pad=mat[:ny*ky, :nx*kx, ...]\n",
        "\n",
        "    new_shape=(ny,ky,nx,kx)+mat.shape[2:]\n",
        "\n",
        "    if method=='max':\n",
        "        result=jnp.nanmax(mat_pad.reshape(new_shape),axis=(1,3))\n",
        "    else:\n",
        "        result=jnp.nanmean(mat_pad.reshape(new_shape),axis=(1,3))\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "9FvAkyJ3zRdP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialize Model\n",
        "Now that we have some idea what this special layer is we can then start initializing the weights of the model. We realize that we want to randomly sample the filter weights and then we want to randomly sample the weights and biases of the fully connected neural network. Thus we have the following: \n",
        "\n",
        "We create the data structure like this: a dictionary which contains the filters to the convolutional mode and then we construct the weights for the fully connected and it is stored in a dictionary!\n",
        "\n",
        "However in order to string these layers together we need to make sure the shapes match!! Thus we need to do the following:"
      ],
      "metadata": {
        "id": "5GdNn3tK0pPf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_output_pooling_shape(image, filter):\n",
        "  Hout = image[0] - filter[0] + 1\n",
        "  Wout = image[1] - filter[1] + 1\n",
        "\n",
        "  return ( Hout//2, Wout//2, filter[2])\n",
        "\n",
        "\n",
        "def init_conv_model(filters, layer_widths, img_shape, parent_key, scale =0.01):\n",
        "  # This first part is the convolutional layers\n",
        "  conv_layers = []\n",
        "  keys = jax.random.split(parent_key,num=len(filters))\n",
        "\n",
        "  image_shape = img_shape\n",
        "\n",
        "  for curr_filter, kernel_key in zip(filters, keys):\n",
        "    conv_layers.append(scale*jax.random.normal(kernel_key, shape=curr_filter))\n",
        "    image_shape = calc_output_pooling_shape(image_shape, curr_filter)\n",
        "\n",
        "  # then we flatten the layers into a single vector\n",
        "  flatten_dimension = image_shape[0]*image_shape[1]*image_shape[2]\n",
        "  in_width = layer_widths[0]\n",
        "  fully_connected  = [] \n",
        "\n",
        "  keys = jax.random.split(parent_key,num=len(layer_widths)-1)\n",
        "  weight_key, bias_key = jax.random.split(keys[0])\n",
        "  fully_connected.append(\n",
        "                  [scale*jax.random.normal(weight_key, shape=(in_width, flatten_dimension)),\n",
        "                  scale*jax.random.normal(bias_key, shape=(in_width,))]\n",
        "  )\n",
        "  # then we feed it properly through the fully connected! This makes sures the shape\n",
        "  # is correct\n",
        "  for in_width, out_width, key in zip(layer_widths[:-1], layer_widths[1:], keys):\n",
        "    weight_key, bias_key = jax.random.split(key)\n",
        "    fully_connected.append(\n",
        "                   [scale*jax.random.normal(weight_key, shape=(out_width, in_width)),\n",
        "                    scale*jax.random.normal(bias_key, shape=(out_width,))]\n",
        "    )\n",
        "  params = {}\n",
        "  params['conv_weights'] = conv_layers\n",
        "  params['full_connected_weights'] = fully_connected\n",
        "  return params\n",
        "\n",
        "filters = [(3,3,16), (3,3,64)]\n",
        "layers = [784, 512, 256, 10]\n",
        "rng = jax.random.PRNGKey(seed=0)\n",
        "\n",
        "\n",
        "convolutional_model_weights = init_conv_model(filters, layers, (28,28), rng, scale =0.01)\n",
        "print(jax.tree_map(lambda x: x.shape, convolutional_model_weights))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tu40A1EG0o4C",
        "outputId": "597efc2e-4c5c-42fe-e9bf-88e4958fc177"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'conv_weights': [(3, 3, 16), (3, 3, 64)], 'full_connected_weights': [[(784, 1600), (784,)], [(512, 784), (512,)], [(256, 512), (256,)], [(10, 256), (10,)]]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feedforward Neural Network\n",
        "\n",
        "Now we need to make the neural network \"alive\" by implementing each of the feed forward processes with the initialized model weights that we have. We get the following:"
      ],
      "metadata": {
        "id": "MAnIgkSc9DVy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def feedforward(params, img):\n",
        "  conv_filters = params['conv_weights']\n",
        "  fully_connected = params['full_connected_weights']\n",
        "  x = img\n",
        "  for filter in conv_filters:\n",
        "    x = conv2d(x, filter)\n",
        "    x = pooling(x,(2,2),method='max',pad=False)\n",
        "    x = jax.nn.relu(x)\n",
        "  # we then unravel the function and flatten it\n",
        "  x = jnp.ravel(x)\n",
        "\n",
        "  hidden_layers = fully_connected[:-1]\n",
        "  activation = x\n",
        "  for w,b in hidden_layers:\n",
        "    activation = jax.nn.relu(jnp.dot(w,activation)+b)\n",
        "\n",
        "  w_last, b_last = fully_connected[-1]\n",
        "  logits = jnp.dot(w_last,activation)+b_last\n",
        "  return logits - logsumexp(logits)\n",
        "\n",
        " \n",
        "filters = [(3,3,3), (3,3,16)]\n",
        "layers = [784, 512, 256, 10]\n",
        "rng = jax.random.PRNGKey(seed=0)\n",
        "\n",
        "convolutional_model_weights = init_conv_model(filters, layers, (28,28), rng, scale =0.01)\n",
        "\n",
        "# LOOK AT THIS VMAP FUNCTION AND REMEMBER IT CLEARLY\n",
        "batched_cnn_predict = vmap(feedforward, in_axes=(None, 0))\n",
        "\n",
        "dummy_imgs_flat = np.random.randn(16, 28,28,1)\n",
        "\n",
        "predictions = batched_cnn_predict(convolutional_model_weights, dummy_imgs_flat)"
      ],
      "metadata": {
        "id": "afG5dECo9CnD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loss Function\n",
        "We once again use the categorical cross entropy loss which is the following: "
      ],
      "metadata": {
        "id": "YWLpX-0OOJHq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_fn(params, x, y):\n",
        "    \"\"\" Compute the multi-class cross-entropy loss \"\"\"\n",
        "    preds = batched_cnn_predict(params, x)\n",
        "    return -np.sum(preds * y)\n",
        "\n",
        "# def loss_fn(params, x, y):\n",
        "#   predictions = batched_cnn_predict(params, imgs)\n",
        "#   return jnp.mean((predictions - y) ** 2)"
      ],
      "metadata": {
        "id": "ldqfSH5SOIGQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loading\n",
        "This is once again some uninteresting data loading and augmentation to scale everything down between 0 and 1 instead of the usual RGB 255 colour scheme.\n",
        "# Preprocess Data\n",
        "We need to massage the data a bit and rescale the data to the shapes we desire namely renormalize the data."
      ],
      "metadata": {
        "id": "bM8E5pLsOYmZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data loading\n",
        "def custom_transform(x):\n",
        "  return np.expand_dims(x/np.max(x), axis=2)\n",
        "train_dataset = MNIST(root='train_mnist', train=True, download=True, transform=custom_transform)\n",
        "test_dataset = MNIST(root='train_mnist', train=False, download=True, transform=custom_transform)"
      ],
      "metadata": {
        "id": "3QphACCtOX3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "wSEyMMqYOvsM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_collate_fn(batch):\n",
        "  transposed_data = list(zip(*batch))\n",
        "  labels = np.array(transposed_data[1])\n",
        "  imgs = np.stack(transposed_data[0])\n",
        "  return imgs, labels\n",
        "\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle = True, collate_fn=custom_collate_fn)\n",
        "batch_data = next(iter(train_loader))\n",
        "imgs = batch_data[0]\n",
        "labels = batch_data[1]\n",
        "print(imgs.shape)"
      ],
      "metadata": {
        "id": "TZUvDg5VOmyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training\n",
        "Now we get to the fun part of training this, this will be the exact same procedure as the MLP training process! The script is slow af and so I only ran just to see that the loss is decreasing. The concept is correct, and in the real world nobody actually does this anymore lmao"
      ],
      "metadata": {
        "id": "dUEvsNFiTRlQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "\n",
        "def update(params, imgs, gt_lbls, lr = 0.01):\n",
        "  loss, grads = value_and_grad(loss_fn)(params,imgs,gt_lbls)\n",
        "  return loss, jax.tree_multimap(lambda p,g:p-lr*g, params, grads)\n",
        "\n",
        "\n",
        "\n",
        "convolutional_model_weights = init_conv_model(filters, layers, (28,28), rng, scale =0.1)\n",
        "\n",
        "\n",
        "for epochs in range(num_epochs):\n",
        "  for count, (imgs, lbls) in enumerate(train_loader):\n",
        "    gt_labels = jax.nn.one_hot(lbls, len(MNIST.classes))\n",
        "    loss, MLP_params = update(convolutional_model_weights, imgs, gt_labels, lr=0.1)\n",
        "    print(loss)\n",
        "  break"
      ],
      "metadata": {
        "id": "HJnQzQlYTRKR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}